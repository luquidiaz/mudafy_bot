# üìä Gu√≠a de An√°lisis de Logs

## üéØ Objetivo

Aprender a leer, analizar y extraer insights de los logs del bot para mejorarlo continuamente.

---

## üìç D√≥nde Est√°n los Logs

### En Desarrollo (Local)

```bash
npm run dev

# Los logs aparecen en la consola
# Ctrl+C para detener
```

### En Producci√≥n (Railway)

**Opci√≥n 1: Dashboard de Railway**
1. Ir a https://railway.app
2. Seleccionar tu proyecto
3. Click en "Deployments"
4. Click en el deployment activo
5. Ver logs en tiempo real

**Opci√≥n 2: CLI de Railway**
```bash
# Instalar CLI
npm install -g @railway/cli

# Login
railway login

# Ver logs en tiempo real
railway logs

# Ver logs con follow (como tail -f)
railway logs --follow

# Exportar logs a archivo
railway logs > logs_$(date +%Y-%m-%d).txt
```

---

## üîç Anatom√≠a de los Logs

### Estructura de un Request Completo

```
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üì® MENSAJE RECIBIDO
   De: 5491234567890
   Mensaje: Cu√°nto vale un depto en Palermo?
   Nombre: Lucas Diaz
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
ü§ñ Procesando con Multi-Agent...
   üîç Cache miss - procesando...
   üß† Clasificaci√≥n: market_data (high) via local (12ms)
      Keywords: precio, palermo
   ‚ö° Fast route (high confidence): market_data
   üìä Ejecutando Market Data Agent...
      ‚è≥ Market Data Agent procesando...
      üîß Market Data Agent ejecut√≥ 2 step(s)
      üîç Market Data Agent us√≥ File Search!
      üí¨ Market Data Agent gener√≥ respuesta
   ‚úÖ Respuesta final recibida: "Seg√∫n datos de Enero 2025:

üìç Palermo
‚Ä¢ Precio promedio: USD..."
   üì§ Respuesta enviada al usuario
   ‚è±Ô∏è  Tiempo total: 2456ms
```

### Componentes Clave

| Emoji | Significado | Qu√© Indica |
|-------|-------------|------------|
| üì® | Mensaje recibido | Inicio de request |
| üéØ | Cache HIT | Respuesta desde cach√© (r√°pido) |
| üîç | Cache miss | Necesita procesar (m√°s lento) |
| üß† | Clasificaci√≥n | Qu√© route decidi√≥ el classifier |
| ‚ö° | Fast route | Sin Orchestrator (optimizado) |
| üé≠ | Orchestrator | Consult√≥ Orchestrator (m√°s lento) |
| üìö/üìä/üí¨ | Agent ejecutado | Qu√© agent respondi√≥ |
| ‚úÖ | Feedback positivo | Usuario satisfecho |
| ‚ùå | Feedback negativo | Usuario insatisfecho |
| ‚è±Ô∏è | Tiempo total | Latencia del request |

---

## üìä An√°lisis B√°sico

### 1. Ver √öltimos 20 Mensajes

```bash
# En Railway
railway logs | grep "üì® MENSAJE RECIBIDO" | tail -20
```

**Output:**
```
üì® MENSAJE RECIBIDO
   De: 5491234567890
   Mensaje: Cu√°nto vale en Palermo?
...
```

### 2. Contar Mensajes por D√≠a

```bash
railway logs | grep "üì® MENSAJE RECIBIDO" | grep "$(date +%Y-%m-%d)" | wc -l
```

**Output:** `45` (45 mensajes hoy)

### 3. Ver Tiempos de Respuesta

```bash
railway logs | grep "‚è±Ô∏è  Tiempo total" | tail -20
```

**Output:**
```
‚è±Ô∏è  Tiempo total: 2456ms
‚è±Ô∏è  Tiempo total: 1834ms
‚è±Ô∏è  Tiempo total: 45ms    ‚Üê Cache hit
‚è±Ô∏è  Tiempo total: 3201ms
```

---

## üî¨ An√°lisis Avanzado

### 1. Top 10 Preguntas M√°s Frecuentes

```bash
railway logs > logs.txt

# Extraer solo los mensajes
cat logs.txt | \
  grep "Mensaje:" | \
  awk -F'Mensaje: ' '{print $2}' | \
  sort | \
  uniq -c | \
  sort -rn | \
  head -10
```

**Output:**
```
  18 Cu√°nto vale un depto en Palermo?
  12 C√≥mo publicar una propiedad?
   9 Qu√© es Mudafy?
   8 Tendencias del mercado
   7 C√≥mo captar leads?
   6 Precio en Belgrano
   5 Mejores pr√°cticas para fotos
   4 Qu√© incluye Mudacademy?
   3 Comisiones de venta
   2 C√≥mo usar F√©nix?
```

**Acci√≥n:**
- Top 3 queries ‚Üí Asegurar respuestas optimizadas
- Nuevas queries frecuentes ‚Üí Agregar al Vector Store

### 2. Distribuci√≥n de Routes

```bash
# Contar cada tipo de route
cat logs.txt | grep "route:" | awk '{print $NF}' | sort | uniq -c | sort -rn
```

**Output:**
```
  245 market_data     (54%)
  156 mudafy_info     (34%)
   55 conversation    (12%)
```

**Interpretaci√≥n:**
- Market Data m√°s usado ‚Üí Asesores buscan datos de mercado
- Knowledge Agent segundo ‚Üí FAQ y gu√≠as √∫tiles
- Conversation bajo ‚Üí Bot usado para trabajo, no chat

### 3. Cache Hit Rate

```bash
# Cache hits
HITS=$(cat logs.txt | grep "üéØ CACHE HIT" | wc -l)

# Cache misses
MISSES=$(cat logs.txt | grep "üîç Cache miss" | wc -l)

# Calcular hit rate
echo "scale=2; $HITS / ($HITS + $MISSES) * 100" | bc
```

**Output:** `32.50%` (32.5% hit rate)

**Objetivo:** >25% es bueno, >40% es excelente

### 4. Fast Path vs Orchestrator

```bash
# Fast paths
FAST=$(cat logs.txt | grep "‚ö° Fast route" | wc -l)

# Orchestrator calls
ORCH=$(cat logs.txt | grep "üé≠ Consultando Orchestrator" | wc -l)

# Calcular fast path rate
echo "scale=2; $FAST / ($FAST + $ORCH) * 100" | bc
```

**Output:** `78.30%` (78.3% fast-path)

**Objetivo:** >75% es bueno, >85% es excelente

### 5. Tiempos de Respuesta Promedio

```bash
cat logs.txt | \
  grep "‚è±Ô∏è  Tiempo total:" | \
  awk '{print $NF}' | \
  sed 's/ms//' | \
  awk '{sum+=$1; count++} END {print sum/count "ms promedio"}'
```

**Output:** `2456.78ms promedio`

**Objetivo:** <3000ms promedio es bueno

### 6. P95 (Percentil 95)

```bash
cat logs.txt | \
  grep "‚è±Ô∏è  Tiempo total:" | \
  awk '{print $NF}' | \
  sed 's/ms//' | \
  sort -n | \
  awk 'BEGIN{c=0} {arr[c++]=$1} END {print arr[int(c*0.95)] "ms (P95)"}'
```

**Output:** `4123ms (P95)`

**Interpretaci√≥n:** 95% de requests toman menos de 4.1s

**Objetivo:** P95 <3500ms

### 7. Feedback Impl√≠cito

```bash
# Feedback positivo
POSITIVE=$(cat logs.txt | grep "‚úÖ Feedback impl√≠cito POSITIVO" | wc -l)

# Feedback negativo
NEGATIVE=$(cat logs.txt | grep "‚ùå Feedback impl√≠cito NEGATIVO" | wc -l)

# Satisfaction rate
echo "scale=2; $POSITIVE / ($POSITIVE + $NEGATIVE) * 100" | bc
```

**Output:** `78.50%` (78.5% satisfacci√≥n)

**Objetivo:** >80% satisfacci√≥n

### 8. Errores

```bash
# Buscar errores
cat logs.txt | grep "‚ùå ERROR:" -A 5
```

**Output:**
```
‚ùå ERROR: Error: Run failed with status: failed
    at OpenAIService.runAssistant
    ...
```

**Acci√≥n:** Identificar patr√≥n y corregir

---

## üõ†Ô∏è Scripts de An√°lisis Automatizados

Ahora creo scripts que puedes ejecutar f√°cilmente:

### Script 1: `analyze-logs.sh`

```bash
#!/bin/bash

# An√°lisis completo de logs

echo "üìä AN√ÅLISIS DE LOGS"
echo "=================="
echo ""

# Total de mensajes
TOTAL=$(grep "üì® MENSAJE RECIBIDO" logs.txt | wc -l)
echo "üì® Total mensajes: $TOTAL"
echo ""

# Top 5 queries
echo "üîù Top 5 Preguntas:"
grep "Mensaje:" logs.txt | \
  awk -F'Mensaje: ' '{print $2}' | \
  sort | uniq -c | sort -rn | head -5
echo ""

# Routes
echo "üìç Distribuci√≥n de Routes:"
grep "route:" logs.txt | awk '{print $NF}' | sort | uniq -c | sort -rn
echo ""

# Cache hit rate
HITS=$(grep "üéØ CACHE HIT" logs.txt | wc -l)
MISSES=$(grep "üîç Cache miss" logs.txt | wc -l)
HIT_RATE=$(echo "scale=2; $HITS / ($HITS + $MISSES) * 100" | bc 2>/dev/null || echo "N/A")
echo "üíæ Cache Hit Rate: $HIT_RATE%"
echo ""

# Fast path rate
FAST=$(grep "‚ö° Fast route" logs.txt | wc -l)
ORCH=$(grep "üé≠ Consultando Orchestrator" logs.txt | wc -l)
FAST_RATE=$(echo "scale=2; $FAST / ($FAST + $ORCH) * 100" | bc 2>/dev/null || echo "N/A")
echo "‚ö° Fast Path Rate: $FAST_RATE%"
echo ""

# Tiempo promedio
AVG_TIME=$(grep "‚è±Ô∏è  Tiempo total:" logs.txt | \
  awk '{print $NF}' | sed 's/ms//' | \
  awk '{sum+=$1; count++} END {print sum/count}' 2>/dev/null || echo "N/A")
echo "‚è±Ô∏è  Tiempo promedio: ${AVG_TIME}ms"
echo ""

# Feedback
POSITIVE=$(grep "‚úÖ Feedback impl√≠cito POSITIVO" logs.txt | wc -l)
NEGATIVE=$(grep "‚ùå Feedback impl√≠cito NEGATIVO" logs.txt | wc -l)
SAT_RATE=$(echo "scale=2; $POSITIVE / ($POSITIVE + $NEGATIVE) * 100" | bc 2>/dev/null || echo "N/A")
echo "üòä Satisfaction Rate: $SAT_RATE%"
echo ""

# Errores
ERRORS=$(grep "‚ùå ERROR:" logs.txt | wc -l)
echo "‚ö†Ô∏è  Errores: $ERRORS"

if [ $ERRORS -gt 0 ]; then
  echo ""
  echo "√öltimos errores:"
  grep "‚ùå ERROR:" logs.txt | tail -3
fi
```

### Script 2: `weekly-report.sh`

```bash
#!/bin/bash

# Reporte semanal autom√°tico

WEEK=$(date +"%Y-W%V")
OUTPUT="report_$WEEK.md"

cat > $OUTPUT << EOF
# üìä Reporte Semanal - Semana $WEEK

## Resumen Ejecutivo

**Per√≠odo:** $(date -d "7 days ago" +%Y-%m-%d) a $(date +%Y-%m-%d)

## M√©tricas Principales

### Volumen
- **Total mensajes:** $(grep "üì® MENSAJE RECIBIDO" logs.txt | wc -l)
- **Usuarios activos:** $(grep "De:" logs.txt | awk '{print $2}' | sort -u | wc -l)
- **Promedio diario:** $(echo "scale=0; $(grep "üì® MENSAJE RECIBIDO" logs.txt | wc -l) / 7" | bc)

### Performance
- **Tiempo promedio:** $(grep "‚è±Ô∏è  Tiempo total:" logs.txt | awk '{print $NF}' | sed 's/ms//' | awk '{sum+=$1; count++} END {print sum/count "ms"}')
- **Cache hit rate:** $(echo "scale=1; $(grep "üéØ CACHE HIT" logs.txt | wc -l) / ($(grep "üéØ CACHE HIT" logs.txt | wc -l) + $(grep "üîç Cache miss" logs.txt | wc -l)) * 100" | bc)%
- **Fast path rate:** $(echo "scale=1; $(grep "‚ö° Fast route" logs.txt | wc -l) / ($(grep "‚ö° Fast route" logs.txt | wc -l) + $(grep "üé≠ Consultando Orchestrator" logs.txt | wc -l)) * 100" | bc)%

### Calidad
- **Satisfaction rate:** $(echo "scale=1; $(grep "‚úÖ Feedback impl√≠cito POSITIVO" logs.txt | wc -l) / ($(grep "‚úÖ Feedback impl√≠cito POSITIVO" logs.txt | wc -l) + $(grep "‚ùå Feedback impl√≠cito NEGATIVO" logs.txt | wc -l)) * 100" | bc)%
- **Errores totales:** $(grep "‚ùå ERROR:" logs.txt | wc -l)

## Top 10 Preguntas

\`\`\`
$(grep "Mensaje:" logs.txt | awk -F'Mensaje: ' '{print $2}' | sort | uniq -c | sort -rn | head -10)
\`\`\`

## Distribuci√≥n de Routes

\`\`\`
$(grep "route:" logs.txt | awk '{print $NF}' | sort | uniq -c | sort -rn)
\`\`\`

## Acciones Recomendadas

- [ ] Revisar top 3 preguntas y optimizar respuestas
- [ ] Agregar keywords para queries frecuentes mal ruteadas
- [ ] Actualizar Vector Store con nuevas FAQs
- [ ] Revisar errores si >5% de requests

---
_Generado autom√°ticamente el $(date +"%Y-%m-%d %H:%M")_
EOF

echo "‚úÖ Reporte generado: $OUTPUT"
cat $OUTPUT
```

---

## üìà Dashboard Semanal (Template)

Crea un archivo `dashboard_template.md`:

```markdown
# üìä Dashboard Semanal - Semana [NUM]

**Per√≠odo:** [FECHA_INICIO] a [FECHA_FIN]

## üéØ M√©tricas Principales

| M√©trica | Valor | Objetivo | Estado |
|---------|-------|----------|--------|
| Total Mensajes | [X] | - | - |
| Usuarios Activos | [X] | - | - |
| Tiempo Promedio | [X]ms | <3000ms | [‚úÖ/‚ö†Ô∏è/‚ùå] |
| Cache Hit Rate | [X]% | >25% | [‚úÖ/‚ö†Ô∏è/‚ùå] |
| Fast Path Rate | [X]% | >75% | [‚úÖ/‚ö†Ô∏è/‚ùå] |
| Satisfaction Rate | [X]% | >80% | [‚úÖ/‚ö†Ô∏è/‚ùå] |
| Errores | [X] | <5% | [‚úÖ/‚ö†Ô∏è/‚ùå] |

## üìä Distribuci√≥n de Routes

| Route | Count | % |
|-------|-------|---|
| Market Data | [X] | [X]% |
| Knowledge | [X] | [X]% |
| Conversation | [X] | [X]% |

## üîù Top 5 Preguntas

1. [Query 1] ([X] veces)
2. [Query 2] ([X] veces)
3. [Query 3] ([X] veces)
4. [Query 4] ([X] veces)
5. [Query 5] ([X] veces)

## üß† Aprendizaje del Bot

- Keywords aprendidas esta semana: [+X]
- Keywords aprendidas total: [X]
- Fast path rate vs semana anterior: [‚Üë/‚Üì/‚Üí] [X]%

## üìù Acciones Tomadas

- [ ] [Acci√≥n 1]
- [ ] [Acci√≥n 2]
- [ ] [Acci√≥n 3]

## üéØ Plan Pr√≥xima Semana

1. [Acci√≥n 1]
2. [Acci√≥n 2]
3. [Acci√≥n 3]

## üìå Notas

[Observaciones, patrones detectados, ideas para mejorar]

---
_Completado el: [FECHA]_
```

---

## üöÄ Workflow Recomendado

### Viernes (15 minutos)

```bash
# 1. Exportar logs de la semana
railway logs > logs_$(date +%Y-%m-%d).txt

# 2. Ejecutar an√°lisis
bash analyze-logs.sh

# 3. Generar reporte
bash weekly-report.sh

# 4. Completar dashboard template
# (manual, con los datos del reporte)

# 5. Identificar acciones
# - ¬øNuevas FAQs necesarias?
# - ¬øKeywords para agregar?
# - ¬øErrores recurrentes?
```

### Lunes (5 minutos)

```bash
# Implementar acciones identificadas
# - Agregar keywords
# - Actualizar Vector Store
# - Fix de errores
```

---

## üîç Patrones Comunes

### Patr√≥n 1: Query Repetida

```
üì® Usuario: "Cu√°nto vale en N√∫√±ez?"
ü§ñ Bot: [Respuesta gen√©rica]
üì® Usuario: "No ten√©s datos de N√∫√±ez?"
‚ùå Feedback negativo detectado
```

**Acci√≥n:** Agregar datos de N√∫√±ez al market_data.json

### Patr√≥n 2: Route Incorrecto

```
üì® Usuario: "Qu√© funciones tiene F√©nix?"
üß† Clasificaci√≥n: conversation (high)  ‚Üê ERROR
üí¨ Ejecutando Conversation Agent...
üì® Usuario: "No, pregunto por el CRM"
‚ùå Feedback negativo detectado
```

**Acci√≥n:** Agregar "funciones" y "fenix" como keywords de mudafy_info

### Patr√≥n 3: Respuestas Lentas

```
‚è±Ô∏è  Tiempo total: 5234ms  ‚Üê Muy lento
‚è±Ô∏è  Tiempo total: 4891ms
‚è±Ô∏è  Tiempo total: 5012ms
```

**Posibles causas:**
- File Search lento ‚Üí Reducir tama√±o de Vector Store
- Orchestrator siempre activo ‚Üí Mejorar keywords
- Sin cach√© ‚Üí Normal en primeras semanas

---

## üìö Queries √ötiles

```bash
# Usuarios √∫nicos hoy
cat logs.txt | grep "De:" | awk '{print $2}' | sort -u | wc -l

# Mensajes por hora
cat logs.txt | grep "üì® MENSAJE RECIBIDO" | awk '{print $1}' | cut -d: -f1 | sort | uniq -c

# Queries que causaron errores
cat logs.txt | grep -B 10 "‚ùå ERROR:" | grep "Mensaje:"

# Keywords m√°s aprendidas
cat logs.txt | grep "Aprendiendo:" | awk -F'"' '{print $2}' | sort | uniq -c | sort -rn

# Respuestas m√°s largas
cat logs.txt | grep "‚úÖ Respuesta final recibida" | awk '{print length, $0}' | sort -rn | head -10
```

---

## üéì Tips y Trucos

1. **Usa `grep` con contexto**
   ```bash
   grep -A 5 "‚ùå ERROR:"  # 5 l√≠neas despu√©s
   grep -B 5 "‚ùå ERROR:"  # 5 l√≠neas antes
   grep -C 5 "‚ùå ERROR:"  # 5 l√≠neas antes y despu√©s
   ```

2. **Filtra por fecha**
   ```bash
   grep "2025-02-15" logs.txt | grep "üì® MENSAJE"
   ```

3. **Busca patrones espec√≠ficos**
   ```bash
   # Mensajes de un usuario
   grep "De: 5491234567890" logs.txt -A 2

   # Solo Market Data queries
   grep "market_data" logs.txt -B 10 | grep "Mensaje:"
   ```

4. **Export a CSV para Excel**
   ```bash
   echo "Timestamp,User,Message,Route,Time" > export.csv
   # Parsear logs y agregar al CSV
   ```

---

**√öltima actualizaci√≥n:** 2025-01-30
**Versi√≥n:** 1.0.0
